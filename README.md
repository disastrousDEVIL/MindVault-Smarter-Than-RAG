MindVault üß†

A Knowledge-Graph Memory Layer for LLMs

MindVault is a backend service that converts documents into a structured knowledge graph and allows Large Language Models (LLMs) to answer questions using only stored knowledge.

This project focuses on memory correctness, traceability, and structure, not chat history or vector-only retrieval.

‚∏ª

What MindVault Is
	‚Ä¢	A memory service, not a chatbot
	‚Ä¢	Stores knowledge as atomic facts
	‚Ä¢	Uses a knowledge graph, not raw text chunks
	‚Ä¢	Answers are grounded strictly in stored memory
	‚Ä¢	Supports multiple documents with shared entities
	‚Ä¢	Provides graph visualization for inspection
‚∏ª
Core Idea

Instead of retrieving text chunks and hoping the model reasons correctly, MindVault:
	1.	Extracts atomic facts from documents
	2.	Stores them as entities and relationships
	3.	Builds a knowledge graph
	4.	Retrieves structured facts
	5.	Uses an LLM only to compose answers from memory

If a fact is not stored, it cannot appear in the answer.

‚∏ª

Architecture Overview

Document
   ‚Üì
LLM (fact extraction)
   ‚Üì
Validated atomic facts
   ‚Üì
Knowledge Graph (Cognee)
   ‚Üì
Fact retrieval
   ‚Üì
LLM (answer generation)

LLMs never bypass memory.

‚∏ª

Memory Model

Atomic Fact

The fundamental unit of memory:

Entity ‚Üí Relation ‚Üí Entity / Value

Example:
	‚Ä¢	LangGraph ‚Üí supports ‚Üí cycles
	‚Ä¢	LangChain ‚Üí provides ‚Üí linear chains

Each fact stores:
	‚Ä¢	subject
	‚Ä¢	relation
	‚Ä¢	object
	‚Ä¢	confidence
	‚Ä¢	source document ID

‚∏ª

Tech Stack
	‚Ä¢	Python: 3.11 (required)
	‚Ä¢	API: FastAPI
	‚Ä¢	LLM: OpenAI API
	‚Ä¢	Memory Engine: Cognee
	‚Ä¢	Visualization: Cognee graph visualizer (HTML)

‚∏ª

Prerequisites
	‚Ä¢	Python 3.11
	‚Ä¢	OpenAI API key
	‚Ä¢	pip and virtualenv

‚ö†Ô∏è Python 3.12+ is not recommended due to dependency constraints.

‚∏ª

Installation

git clone https://github.com/your-username/mindvault.git
cd mindvault

python3.11 -m venv venv
source venv/bin/activate

pip install -r requirements.txt


‚∏ª

Environment Variables

Create a .env file in the project root:

OPENAI_API_KEY=sk-your-openai-key
OPENAI_MODEL=gpt-4.1-mini
DEBUG=false

OPENAI_MODEL defaults to gpt-4.1-mini if not set.


‚∏ª

Running the Server

uvicorn app.main:app --reload

Open Swagger UI:

http://127.0.0.1:8000/docs


‚∏ª

API Endpoints

1. Ingest a Document

POST /ingest

{
  "document_id": "doc_langgraph",
  "title": "LangGraph Overview",
  "content": "LangGraph supports stateful workflows and allows cycles."
}

Response:

{
  "status": "success",
  "facts_stored": 2
}


‚∏ª

2. Ask a Question

POST /query

{
  "question": "How does LangGraph differ from LangChain?"
}

Response:

{
  "answer": "LangGraph supports stateful workflows and cycles, while LangChain focuses on linear chains.",
  "sources": ["doc_langgraph", "doc_langchain"]
}


‚∏ª

3. Visualize the Knowledge Graph

GET /graph
	‚Ä¢	Generates an HTML file
	‚Ä¢	If output_path is provided, returns the HTML file directly
	‚Ä¢	If output_path is omitted, writes to Cognee's default location (usually your home directory)
	‚Ä¢	Displays entities and relationships visually

Optional query params:
	‚Ä¢	output_path: where to write the HTML file
	‚Ä¢	dataset_name: Cognee dataset to visualize

Example response (no output_path):

{
  "status": "success",
  "message": "Graph written to Cognee's default location (home directory)."
}

Open the file in a browser to inspect memory.

‚∏ª

Expected Behavior

Correct Answers
	‚Ä¢	Answers combine facts from multiple documents
	‚Ä¢	Sources are always listed
	‚Ä¢	No hallucinations

Failure Case

If memory lacks information:

{
  "answer": "Not enough information in memory to answer this question.",
  "sources": []
}

This is a successful outcome, not an error.

‚∏ª

Folder Structure

MindVault/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py        # FastAPI wiring
‚îÇ   ‚îú‚îÄ‚îÄ settings.py    # env loading
‚îÇ   ‚îú‚îÄ‚îÄ llm.py         # OpenAI client
‚îÇ   ‚îú‚îÄ‚îÄ ingest.py      # document ‚Üí facts
‚îÇ   ‚îú‚îÄ‚îÄ memory.py      # Cognee integration
‚îÇ   ‚îî‚îÄ‚îÄ retrieve.py    # fact retrieval
‚îÇ
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îú‚îÄ‚îÄ sample_doc.md
‚îÇ   ‚îî‚îÄ‚îÄ sample_query.txt
‚îÇ
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ requirements.txt


‚∏ª

Why This Project Matters

Most RAG systems:
	‚Ä¢	Retrieve text chunks
	‚Ä¢	Depend on probabilistic reasoning
	‚Ä¢	Hallucinate silently

MindVault:
	‚Ä¢	Stores knowledge, not text
	‚Ä¢	Makes memory inspectable
	‚Ä¢	Guarantees answer grounding
	‚Ä¢	Scales across documents naturally

This is how LLM memory should actually be built.

‚∏ª

Status

‚úÖ Multi-document ingestion
‚úÖ Knowledge graph memory
‚úÖ Grounded question answering
‚úÖ Graph visualization
‚úÖ Production-ready v1

‚∏ª

License

This project is licensed under the MIT License.

You are free to use, modify, and distribute this software with attribution.
See the LICENSE file for full details.

